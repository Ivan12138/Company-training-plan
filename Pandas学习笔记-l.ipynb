{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas学习笔记\n",
    "\n",
    "![panadas图标](https://extraimage.net/images/2019/09/23/49c74b414c5244690b0adbd47285400f.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.  Pandas是什么\n",
    "\n",
    "> - Pandas是一个强大的分析结构化数据的工具集；\n",
    "> - 它的使用基础是Numpy（提供高性能的矩阵运算）(提供了高级的数据结构与工具)；\n",
    "> - 用于数据挖掘和数据分析，同时也提供数据清洗功能。\n",
    "\n",
    "\n",
    "对于pandas我们主要集中在以下几个方面：<br>\n",
    "- 数据类型\n",
    "- 数据读取\n",
    "- 数据选择\n",
    "- 数据删减\n",
    "- 数据填充"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Pandas基本数据结构\n",
    "\n",
    "Pandas 的数据类型主要有以下几种，它们分别是：Series（一维数组），DataFrame（二维数组），Panel（三维数组），Panel4D（四维数组），PanelND（更多维数组）。其中 Series 和 DataFrame 应用的最为广泛，几乎占据了使用频率 90% 以上。\n",
    "\n",
    "> - **series**:类似于Numpy中的ndarray,差别主要体现在两个方面：\n",
    "  - - series中的数据可以是不同类型的，ndarray中的数据必须是同类型的；\n",
    "  - - series的索引可以为字符型类型；\n",
    "  \n",
    "> Series 基本结构如下：\n",
    "\n",
    "```python\n",
    "    pandas.Series(data=None, index=None，dtype=None,Name=None)\n",
    "```\n",
    "- - 其中，data 可以是字典，或者NumPy 里的 ndarray 对象等。index 是数据索引，索引是 Pandas 数据结构中的一大特性，它主要的功能是帮助我们更快速地定位数据。  \n",
    "  \n",
    "> - **dataframe**: 具有行索引和列索引的数据，类似于关系数据库中的关系数据。你可以把 DataFrame 看成是 Series 的扩展类型，它仿佛是由多个 Series 拼合而成。它和 Series 的直观区别在于，数据不但具有行索引，且具有列索引。\n",
    "\n",
    "![dataframe](https://doc.shiyanlou.com/courses/uid214893-20190531-1559284057250)\n",
    "\n",
    "> 使用pandas必须首先导入pandas库 import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.24.2\n",
      "Math       90\n",
      "PE         83\n",
      "English    88\n",
      "Chinese    98\n",
      "Physics    80\n",
      "dtype: int32\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "print(pd.__version__)\n",
    "\n",
    "mine=pd.Series(np.random.randint(80,100,5),index=[\"Math\",\"PE\",\"English\",\"Chinese\",\"Physics\"])\n",
    "print(mine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Math', 'PE', 'English', 'Chinese', 'Physics'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# 查看索引值\n",
    "print(mine.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90\n",
      "90\n"
     ]
    }
   ],
   "source": [
    "#series 获取数据的方法同numpy类似，但其不支持负索引\n",
    "print(mine[0])\n",
    "print(mine.Math)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**练习题1：** <br>\n",
    "如上所示，该 Series 的数据值是 10, 20, 30，索引为 a, b, c，数据值的类型默认识别为 int64。你可以通过 type 来确认 s 的类型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 DataFrame\n",
    "<br>\n",
    "DataFrame的基本用法如下：\n",
    "\n",
    "\n",
    "```python\n",
    "    pandas.DataFrame(data=None, index=None, columns=None)                    \n",
    "```\n",
    "\n",
    "区别于 Series，其增加了 columns 列索引。DataFrame 可以由以下多个类型的数据构建：\n",
    "\n",
    "- 一维数组、列表、字典或者 Series 字典。\n",
    "- 二维或者结构化的 numpy.ndarray。\n",
    "- 一个 Series 或者另一个 DataFrame。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   one  two\n",
      "0    1    4\n",
      "1    2    5\n",
      "2    3    6\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'one': pd.Series([1, 2, 3]),\n",
    "                   'two': pd.Series([4, 5, 6])})\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   one  two\n",
      "0    1    4\n",
      "1    2    5\n",
      "2    3    7\n"
     ]
    }
   ],
   "source": [
    "cd = pd.DataFrame({'one':{0:1,1:2,2:3},\n",
    "              'two':{0:4,1:5,2:7}})\n",
    "print(cd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   one  two\n",
      "0    1    4\n",
      "1    2    5\n",
      "2    3    6\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "df = pd.DataFrame([{'one': 1, 'two': 4},\n",
    "                   {'one': 2, 'two': 5},\n",
    "                   {'one': 3, 'two': 6}])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**练习2：**\n",
    "<br>\n",
    "分别使用字典和多维字典数组构建两个DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0   1   2   3\n",
      "0  76  85  76  81\n",
      "1  84  88  83  84\n",
      "2  78  79  81  81\n",
      "     0    1    2    3    4\n",
      "0  1.0  0.0  0.0  0.0  0.0\n",
      "1  0.0  1.0  0.0  0.0  0.0\n",
      "2  0.0  0.0  1.0  0.0  0.0\n",
      "3  0.0  0.0  0.0  1.0  0.0\n",
      "4  0.0  0.0  0.0  0.0  1.0\n"
     ]
    }
   ],
   "source": [
    "# 利用numpy中的多维数组构建dataframe\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(np.random.binomial(100,0.8,(3,4)))\n",
    "print(df)\n",
    "\n",
    "df= pd.DataFrame(np.eye(5))\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**练习3** \n",
    "\n",
    "请使用多维ndarry对象创建两个DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Series 实际上可以被初略看出是只有 1 列数据的 DataFrame。当然，这个说法不严谨，二者的核心区别仍然是 Series 没有列索引。你可以观察如下所示由 NumPy 一维随机数组生成的 Series 和 DataFrame。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    91\n",
      "1    93\n",
      "2    90\n",
      "3    91\n",
      "4    92\n",
      "dtype: int32\n",
      "    0\n",
      "0  92\n",
      "1  93\n",
      "2  99\n",
      "3  94\n",
      "4  93\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# create Series\n",
    "s=pd.Series(np.random.randint(90,100,5))\n",
    "print(s)\n",
    "\n",
    "#create dataframe\n",
    "df=pd.DataFrame(np.random.randint(90,100,5))\n",
    "print(df)\n",
    "\n",
    "# pay more attention to the difference between the series and the dataframe list below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 数据的读取\n",
    "<br>\n",
    "我们想要使用 Pandas 来分析数据，那么首先需要读取数据。大多数情况下，数据都来源于外部的数据文件或者数据库。Pandas 提供了一系列的方法来读取外部数据，非常全面。\n",
    "\n",
    "第一个函数是我们经常用到的读取CSV文件的函数：pd.read_csv(相对路径文件|文件的URL)\n",
    "\n",
    "```python\n",
    "    df = pd.read_csv(\"https://labfile.oss.aliyuncs.com/courses/906/los_census.csv\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Zip Code  Total Population  Median Age  Total Males  Total Females  \\\n",
      "0     91371                 1        73.5            0              1   \n",
      "1     90001             57110        26.6        28468          28642   \n",
      "2     90002             51223        25.5        24876          26347   \n",
      "3     90003             66266        26.3        32631          33635   \n",
      "4     90004             62180        34.8        31302          30878   \n",
      "\n",
      "   Total Households  Average Household Size  \n",
      "0                 1                    1.00  \n",
      "1             12971                    4.40  \n",
      "2             11731                    4.36  \n",
      "3             15642                    4.22  \n",
      "4             22547                    2.73  \n",
      "     Zip Code  Total Population  Median Age  Total Males  Total Females  \\\n",
      "316     93560             18910        32.4         9491           9419   \n",
      "317     93563               388        44.5          263            125   \n",
      "318     93591              7285        30.9         3653           3632   \n",
      "\n",
      "     Total Households  Average Household Size  \n",
      "316              6469                    2.92  \n",
      "317               103                    2.53  \n",
      "318              1982                    3.67  \n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"https://labfile.oss.aliyuncs.com/courses/906/los_census.csv\")\n",
    "print(df.head())\n",
    "print(df.tail(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DataFrame 是 Pandas 构成的核心。一切的数据，无论是外部读取还是自行生成，我们都需要先将其转换为 Pandas 的 DataFrame 或者 Series 数据类型。\n",
    "<br>\n",
    "基本原因在与pandas所有针对数据的操作都是基于series和dataframe这两种数据结构进行的。\n",
    "在pandas中除了有pd.read_csv()这种从csv数据中获取数据的方法之外，还有："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function read_table in module pandas.io.parsers:\n",
      "\n",
      "read_table(filepath_or_buffer, sep=False, delimiter=None, header='infer', names=None, index_col=None, usecols=None, squeeze=False, prefix=None, mangle_dupe_cols=True, dtype=None, engine=None, converters=None, true_values=None, false_values=None, skipinitialspace=False, skiprows=None, skipfooter=0, nrows=None, na_values=None, keep_default_na=True, na_filter=True, verbose=False, skip_blank_lines=True, parse_dates=False, infer_datetime_format=False, keep_date_col=False, date_parser=None, dayfirst=False, iterator=False, chunksize=None, compression='infer', thousands=None, decimal=b'.', lineterminator=None, quotechar='\"', quoting=0, doublequote=True, escapechar=None, comment=None, encoding=None, dialect=None, tupleize_cols=None, error_bad_lines=True, warn_bad_lines=True, delim_whitespace=False, low_memory=True, memory_map=False, float_precision=None)\n",
      "    Read general delimited file into DataFrame.\n",
      "    \n",
      "    .. deprecated:: 0.24.0\n",
      "    Use :func:`pandas.read_csv` instead, passing ``sep='\\t'`` if necessary.\n",
      "    \n",
      "    Also supports optionally iterating or breaking of the file\n",
      "    into chunks.\n",
      "    \n",
      "    Additional help can be found in the online docs for\n",
      "    `IO Tools <http://pandas.pydata.org/pandas-docs/stable/io.html>`_.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    filepath_or_buffer : str, path object, or file-like object\n",
      "        Any valid string path is acceptable. The string could be a URL. Valid\n",
      "        URL schemes include http, ftp, s3, and file. For file URLs, a host is\n",
      "        expected. A local file could be: file://localhost/path/to/table.csv.\n",
      "    \n",
      "        If you want to pass in a path object, pandas accepts either\n",
      "        ``pathlib.Path`` or ``py._path.local.LocalPath``.\n",
      "    \n",
      "        By file-like object, we refer to objects with a ``read()`` method, such as\n",
      "        a file handler (e.g. via builtin ``open`` function) or ``StringIO``.\n",
      "    sep : str, default '\\\\t' (tab-stop)\n",
      "        Delimiter to use. If sep is None, the C engine cannot automatically detect\n",
      "        the separator, but the Python parsing engine can, meaning the latter will\n",
      "        be used and automatically detect the separator by Python's builtin sniffer\n",
      "        tool, ``csv.Sniffer``. In addition, separators longer than 1 character and\n",
      "        different from ``'\\s+'`` will be interpreted as regular expressions and\n",
      "        will also force the use of the Python parsing engine. Note that regex\n",
      "        delimiters are prone to ignoring quoted data. Regex example: ``'\\r\\t'``.\n",
      "    delimiter : str, default ``None``\n",
      "        Alias for sep.\n",
      "    header : int, list of int, default 'infer'\n",
      "        Row number(s) to use as the column names, and the start of the\n",
      "        data.  Default behavior is to infer the column names: if no names\n",
      "        are passed the behavior is identical to ``header=0`` and column\n",
      "        names are inferred from the first line of the file, if column\n",
      "        names are passed explicitly then the behavior is identical to\n",
      "        ``header=None``. Explicitly pass ``header=0`` to be able to\n",
      "        replace existing names. The header can be a list of integers that\n",
      "        specify row locations for a multi-index on the columns\n",
      "        e.g. [0,1,3]. Intervening rows that are not specified will be\n",
      "        skipped (e.g. 2 in this example is skipped). Note that this\n",
      "        parameter ignores commented lines and empty lines if\n",
      "        ``skip_blank_lines=True``, so ``header=0`` denotes the first line of\n",
      "        data rather than the first line of the file.\n",
      "    names : array-like, optional\n",
      "        List of column names to use. If file contains no header row, then you\n",
      "        should explicitly pass ``header=None``. Duplicates in this list will cause\n",
      "        a ``UserWarning`` to be issued.\n",
      "    index_col : int, sequence or bool, optional\n",
      "        Column to use as the row labels of the DataFrame. If a sequence is given, a\n",
      "        MultiIndex is used. If you have a malformed file with delimiters at the end\n",
      "        of each line, you might consider ``index_col=False`` to force pandas to\n",
      "        not use the first column as the index (row names).\n",
      "    usecols : list-like or callable, optional\n",
      "        Return a subset of the columns. If list-like, all elements must either\n",
      "        be positional (i.e. integer indices into the document columns) or strings\n",
      "        that correspond to column names provided either by the user in `names` or\n",
      "        inferred from the document header row(s). For example, a valid list-like\n",
      "        `usecols` parameter would be ``[0, 1, 2]`` or ``['foo', 'bar', 'baz']``.\n",
      "        Element order is ignored, so ``usecols=[0, 1]`` is the same as ``[1, 0]``.\n",
      "        To instantiate a DataFrame from ``data`` with element order preserved use\n",
      "        ``pd.read_csv(data, usecols=['foo', 'bar'])[['foo', 'bar']]`` for columns\n",
      "        in ``['foo', 'bar']`` order or\n",
      "        ``pd.read_csv(data, usecols=['foo', 'bar'])[['bar', 'foo']]``\n",
      "        for ``['bar', 'foo']`` order.\n",
      "    \n",
      "        If callable, the callable function will be evaluated against the column\n",
      "        names, returning names where the callable function evaluates to True. An\n",
      "        example of a valid callable argument would be ``lambda x: x.upper() in\n",
      "        ['AAA', 'BBB', 'DDD']``. Using this parameter results in much faster\n",
      "        parsing time and lower memory usage.\n",
      "    squeeze : bool, default False\n",
      "        If the parsed data only contains one column then return a Series.\n",
      "    prefix : str, optional\n",
      "        Prefix to add to column numbers when no header, e.g. 'X' for X0, X1, ...\n",
      "    mangle_dupe_cols : bool, default True\n",
      "        Duplicate columns will be specified as 'X', 'X.1', ...'X.N', rather than\n",
      "        'X'...'X'. Passing in False will cause data to be overwritten if there\n",
      "        are duplicate names in the columns.\n",
      "    dtype : Type name or dict of column -> type, optional\n",
      "        Data type for data or columns. E.g. {'a': np.float64, 'b': np.int32,\n",
      "        'c': 'Int64'}\n",
      "        Use `str` or `object` together with suitable `na_values` settings\n",
      "        to preserve and not interpret dtype.\n",
      "        If converters are specified, they will be applied INSTEAD\n",
      "        of dtype conversion.\n",
      "    engine : {'c', 'python'}, optional\n",
      "        Parser engine to use. The C engine is faster while the python engine is\n",
      "        currently more feature-complete.\n",
      "    converters : dict, optional\n",
      "        Dict of functions for converting values in certain columns. Keys can either\n",
      "        be integers or column labels.\n",
      "    true_values : list, optional\n",
      "        Values to consider as True.\n",
      "    false_values : list, optional\n",
      "        Values to consider as False.\n",
      "    skipinitialspace : bool, default False\n",
      "        Skip spaces after delimiter.\n",
      "    skiprows : list-like, int or callable, optional\n",
      "        Line numbers to skip (0-indexed) or number of lines to skip (int)\n",
      "        at the start of the file.\n",
      "    \n",
      "        If callable, the callable function will be evaluated against the row\n",
      "        indices, returning True if the row should be skipped and False otherwise.\n",
      "        An example of a valid callable argument would be ``lambda x: x in [0, 2]``.\n",
      "    skipfooter : int, default 0\n",
      "        Number of lines at bottom of file to skip (Unsupported with engine='c').\n",
      "    nrows : int, optional\n",
      "        Number of rows of file to read. Useful for reading pieces of large files.\n",
      "    na_values : scalar, str, list-like, or dict, optional\n",
      "        Additional strings to recognize as NA/NaN. If dict passed, specific\n",
      "        per-column NA values.  By default the following values are interpreted as\n",
      "        NaN: '', '#N/A', '#N/A N/A', '#NA', '-1.#IND', '-1.#QNAN', '-NaN', '-nan',\n",
      "        '1.#IND', '1.#QNAN', 'N/A', 'NA', 'NULL', 'NaN', 'n/a', 'nan',\n",
      "        'null'.\n",
      "    keep_default_na : bool, default True\n",
      "        Whether or not to include the default NaN values when parsing the data.\n",
      "        Depending on whether `na_values` is passed in, the behavior is as follows:\n",
      "    \n",
      "        * If `keep_default_na` is True, and `na_values` are specified, `na_values`\n",
      "          is appended to the default NaN values used for parsing.\n",
      "        * If `keep_default_na` is True, and `na_values` are not specified, only\n",
      "          the default NaN values are used for parsing.\n",
      "        * If `keep_default_na` is False, and `na_values` are specified, only\n",
      "          the NaN values specified `na_values` are used for parsing.\n",
      "        * If `keep_default_na` is False, and `na_values` are not specified, no\n",
      "          strings will be parsed as NaN.\n",
      "    \n",
      "        Note that if `na_filter` is passed in as False, the `keep_default_na` and\n",
      "        `na_values` parameters will be ignored.\n",
      "    na_filter : bool, default True\n",
      "        Detect missing value markers (empty strings and the value of na_values). In\n",
      "        data without any NAs, passing na_filter=False can improve the performance\n",
      "        of reading a large file.\n",
      "    verbose : bool, default False\n",
      "        Indicate number of NA values placed in non-numeric columns.\n",
      "    skip_blank_lines : bool, default True\n",
      "        If True, skip over blank lines rather than interpreting as NaN values.\n",
      "    parse_dates : bool or list of int or names or list of lists or dict, default False\n",
      "        The behavior is as follows:\n",
      "    \n",
      "        * boolean. If True -> try parsing the index.\n",
      "        * list of int or names. e.g. If [1, 2, 3] -> try parsing columns 1, 2, 3\n",
      "          each as a separate date column.\n",
      "        * list of lists. e.g.  If [[1, 3]] -> combine columns 1 and 3 and parse as\n",
      "          a single date column.\n",
      "        * dict, e.g. {'foo' : [1, 3]} -> parse columns 1, 3 as date and call\n",
      "          result 'foo'\n",
      "    \n",
      "        If a column or index cannot be represented as an array of datetimes,\n",
      "        say because of an unparseable value or a mixture of timezones, the column\n",
      "        or index will be returned unaltered as an object data type. For\n",
      "        non-standard datetime parsing, use ``pd.to_datetime`` after\n",
      "        ``pd.read_csv``. To parse an index or column with a mixture of timezones,\n",
      "        specify ``date_parser`` to be a partially-applied\n",
      "        :func:`pandas.to_datetime` with ``utc=True``. See\n",
      "        :ref:`io.csv.mixed_timezones` for more.\n",
      "    \n",
      "        Note: A fast-path exists for iso8601-formatted dates.\n",
      "    infer_datetime_format : bool, default False\n",
      "        If True and `parse_dates` is enabled, pandas will attempt to infer the\n",
      "        format of the datetime strings in the columns, and if it can be inferred,\n",
      "        switch to a faster method of parsing them. In some cases this can increase\n",
      "        the parsing speed by 5-10x.\n",
      "    keep_date_col : bool, default False\n",
      "        If True and `parse_dates` specifies combining multiple columns then\n",
      "        keep the original columns.\n",
      "    date_parser : function, optional\n",
      "        Function to use for converting a sequence of string columns to an array of\n",
      "        datetime instances. The default uses ``dateutil.parser.parser`` to do the\n",
      "        conversion. Pandas will try to call `date_parser` in three different ways,\n",
      "        advancing to the next if an exception occurs: 1) Pass one or more arrays\n",
      "        (as defined by `parse_dates`) as arguments; 2) concatenate (row-wise) the\n",
      "        string values from the columns defined by `parse_dates` into a single array\n",
      "        and pass that; and 3) call `date_parser` once for each row using one or\n",
      "        more strings (corresponding to the columns defined by `parse_dates`) as\n",
      "        arguments.\n",
      "    dayfirst : bool, default False\n",
      "        DD/MM format dates, international and European format.\n",
      "    iterator : bool, default False\n",
      "        Return TextFileReader object for iteration or getting chunks with\n",
      "        ``get_chunk()``.\n",
      "    chunksize : int, optional\n",
      "        Return TextFileReader object for iteration.\n",
      "        See the `IO Tools docs\n",
      "        <http://pandas.pydata.org/pandas-docs/stable/io.html#io-chunking>`_\n",
      "        for more information on ``iterator`` and ``chunksize``.\n",
      "    compression : {'infer', 'gzip', 'bz2', 'zip', 'xz', None}, default 'infer'\n",
      "        For on-the-fly decompression of on-disk data. If 'infer' and\n",
      "        `filepath_or_buffer` is path-like, then detect compression from the\n",
      "        following extensions: '.gz', '.bz2', '.zip', or '.xz' (otherwise no\n",
      "        decompression). If using 'zip', the ZIP file must contain only one data\n",
      "        file to be read in. Set to None for no decompression.\n",
      "    \n",
      "        .. versionadded:: 0.18.1 support for 'zip' and 'xz' compression.\n",
      "    \n",
      "    thousands : str, optional\n",
      "        Thousands separator.\n",
      "    decimal : str, default '.'\n",
      "        Character to recognize as decimal point (e.g. use ',' for European data).\n",
      "    lineterminator : str (length 1), optional\n",
      "        Character to break file into lines. Only valid with C parser.\n",
      "    quotechar : str (length 1), optional\n",
      "        The character used to denote the start and end of a quoted item. Quoted\n",
      "        items can include the delimiter and it will be ignored.\n",
      "    quoting : int or csv.QUOTE_* instance, default 0\n",
      "        Control field quoting behavior per ``csv.QUOTE_*`` constants. Use one of\n",
      "        QUOTE_MINIMAL (0), QUOTE_ALL (1), QUOTE_NONNUMERIC (2) or QUOTE_NONE (3).\n",
      "    doublequote : bool, default ``True``\n",
      "       When quotechar is specified and quoting is not ``QUOTE_NONE``, indicate\n",
      "       whether or not to interpret two consecutive quotechar elements INSIDE a\n",
      "       field as a single ``quotechar`` element.\n",
      "    escapechar : str (length 1), optional\n",
      "        One-character string used to escape other characters.\n",
      "    comment : str, optional\n",
      "        Indicates remainder of line should not be parsed. If found at the beginning\n",
      "        of a line, the line will be ignored altogether. This parameter must be a\n",
      "        single character. Like empty lines (as long as ``skip_blank_lines=True``),\n",
      "        fully commented lines are ignored by the parameter `header` but not by\n",
      "        `skiprows`. For example, if ``comment='#'``, parsing\n",
      "        ``#empty\\na,b,c\\n1,2,3`` with ``header=0`` will result in 'a,b,c' being\n",
      "        treated as the header.\n",
      "    encoding : str, optional\n",
      "        Encoding to use for UTF when reading/writing (ex. 'utf-8'). `List of Python\n",
      "        standard encodings\n",
      "        <https://docs.python.org/3/library/codecs.html#standard-encodings>`_ .\n",
      "    dialect : str or csv.Dialect, optional\n",
      "        If provided, this parameter will override values (default or not) for the\n",
      "        following parameters: `delimiter`, `doublequote`, `escapechar`,\n",
      "        `skipinitialspace`, `quotechar`, and `quoting`. If it is necessary to\n",
      "        override values, a ParserWarning will be issued. See csv.Dialect\n",
      "        documentation for more details.\n",
      "    tupleize_cols : bool, default False\n",
      "        Leave a list of tuples on columns as is (default is to convert to\n",
      "        a MultiIndex on the columns).\n",
      "    \n",
      "        .. deprecated:: 0.21.0\n",
      "           This argument will be removed and will always convert to MultiIndex\n",
      "    \n",
      "    error_bad_lines : bool, default True\n",
      "        Lines with too many fields (e.g. a csv line with too many commas) will by\n",
      "        default cause an exception to be raised, and no DataFrame will be returned.\n",
      "        If False, then these \"bad lines\" will dropped from the DataFrame that is\n",
      "        returned.\n",
      "    warn_bad_lines : bool, default True\n",
      "        If error_bad_lines is False, and warn_bad_lines is True, a warning for each\n",
      "        \"bad line\" will be output.\n",
      "    delim_whitespace : bool, default False\n",
      "        Specifies whether or not whitespace (e.g. ``' '`` or ``'    '``) will be\n",
      "        used as the sep. Equivalent to setting ``sep='\\s+'``. If this option\n",
      "        is set to True, nothing should be passed in for the ``delimiter``\n",
      "        parameter.\n",
      "    \n",
      "        .. versionadded:: 0.18.1 support for the Python parser.\n",
      "    \n",
      "    low_memory : bool, default True\n",
      "        Internally process the file in chunks, resulting in lower memory use\n",
      "        while parsing, but possibly mixed type inference.  To ensure no mixed\n",
      "        types either set False, or specify the type with the `dtype` parameter.\n",
      "        Note that the entire file is read into a single DataFrame regardless,\n",
      "        use the `chunksize` or `iterator` parameter to return the data in chunks.\n",
      "        (Only valid with C parser).\n",
      "    memory_map : bool, default False\n",
      "        If a filepath is provided for `filepath_or_buffer`, map the file object\n",
      "        directly onto memory and access the data directly from there. Using this\n",
      "        option can improve performance because there is no longer any I/O overhead.\n",
      "    float_precision : str, optional\n",
      "        Specifies which converter the C engine should use for floating-point\n",
      "        values. The options are `None` for the ordinary converter,\n",
      "        `high` for the high-precision converter, and `round_trip` for the\n",
      "        round-trip converter.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    DataFrame or TextParser\n",
      "        A comma-separated values (csv) file is returned as two-dimensional\n",
      "        data structure with labeled axes.\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    to_csv : Write DataFrame to a comma-separated values (csv) file.\n",
      "    read_csv : Read a comma-separated values (csv) file into DataFrame.\n",
      "    read_fwf : Read a table of fixed-width formatted lines into DataFrame.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> pd.read_table('data.csv')  # doctest: +SKIP\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "help(pd.read_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 基本操作\n",
    "\n",
    "![DataFrame数据类型示意图](https://doc.shiyanlou.com/courses/uid214893-20190531-1559286555222)\n",
    "\n",
    ">一个 DataFrame 结构大致由 3 部分组成，它们分别是列名称、索引和数据。\n",
    "> - head()与tail():分别用于获取dataframe的首部或或尾部数据；\n",
    "> - describe():快速获取数据集合中的统计特性；\n",
    "> - values: 获取df的numpy形式，可以使用numpy中的方法对数据进行处理；\n",
    "> - index与columns：分别获取数据中的行索引名与列索引名；\n",
    "> - shape:获取数组的形状；"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Zip Code  Total Population  Median Age  Total Males  Total Females  \\\n",
      "0     91371                 1        73.5            0              1   \n",
      "1     90001             57110        26.6        28468          28642   \n",
      "2     90002             51223        25.5        24876          26347   \n",
      "3     90003             66266        26.3        32631          33635   \n",
      "4     90004             62180        34.8        31302          30878   \n",
      "\n",
      "   Total Households  Average Household Size  \n",
      "0                 1                    1.00  \n",
      "1             12971                    4.40  \n",
      "2             11731                    4.36  \n",
      "3             15642                    4.22  \n",
      "4             22547                    2.73  \n",
      "     Zip Code  Total Population  Median Age  Total Males  Total Females  \\\n",
      "314     93552             38158        28.4        18711          19447   \n",
      "315     93553              2138        43.3         1121           1017   \n",
      "316     93560             18910        32.4         9491           9419   \n",
      "317     93563               388        44.5          263            125   \n",
      "318     93591              7285        30.9         3653           3632   \n",
      "\n",
      "     Total Households  Average Household Size  \n",
      "314              9690                    3.93  \n",
      "315               816                    2.62  \n",
      "316              6469                    2.92  \n",
      "317               103                    2.53  \n",
      "318              1982                    3.67  \n",
      "************describe*************\n",
      "           Zip Code  Total Population  Median Age   Total Males  \\\n",
      "count    319.000000        319.000000  319.000000    319.000000   \n",
      "mean   91000.673981      33241.341693   36.527586  16391.564263   \n",
      "std      908.360203      21644.417455    8.692999  10747.495566   \n",
      "min    90001.000000          0.000000    0.000000      0.000000   \n",
      "25%    90243.500000      19318.500000   32.400000   9763.500000   \n",
      "50%    90807.000000      31481.000000   37.100000  15283.000000   \n",
      "75%    91417.000000      44978.000000   41.000000  22219.500000   \n",
      "max    93591.000000     105549.000000   74.000000  52794.000000   \n",
      "\n",
      "       Total Females  Total Households  Average Household Size  \n",
      "count     319.000000        319.000000              319.000000  \n",
      "mean    16849.777429      10964.570533                2.828119  \n",
      "std     10934.986468       6270.646400                0.835658  \n",
      "min         0.000000          0.000000                0.000000  \n",
      "25%      9633.500000       6765.500000                2.435000  \n",
      "50%     16202.000000      10968.000000                2.830000  \n",
      "75%     22690.500000      14889.500000                3.320000  \n",
      "max     53185.000000      31087.000000                4.670000  \n",
      "***************values*************************\n",
      "[[9.1371e+04 1.0000e+00 7.3500e+01 ... 1.0000e+00 1.0000e+00 1.0000e+00]\n",
      " [9.0001e+04 5.7110e+04 2.6600e+01 ... 2.8642e+04 1.2971e+04 4.4000e+00]\n",
      " [9.0002e+04 5.1223e+04 2.5500e+01 ... 2.6347e+04 1.1731e+04 4.3600e+00]\n",
      " ...\n",
      " [9.3560e+04 1.8910e+04 3.2400e+01 ... 9.4190e+03 6.4690e+03 2.9200e+00]\n",
      " [9.3563e+04 3.8800e+02 4.4500e+01 ... 1.2500e+02 1.0300e+02 2.5300e+00]\n",
      " [9.3591e+04 7.2850e+03 3.0900e+01 ... 3.6320e+03 1.9820e+03 3.6700e+00]]\n",
      "***************type*************************\n",
      "<class 'numpy.ndarray'>\n",
      "**************index**************************\n",
      "RangeIndex(start=0, stop=319, step=1)\n",
      "**************columns**************************\n",
      "Index(['Zip Code', 'Total Population', 'Median Age', 'Total Males',\n",
      "       'Total Females', 'Total Households', 'Average Household Size'],\n",
      "      dtype='object')\n",
      "(319, 7)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"https://labfile.oss.aliyuncs.com/courses/906/los_census.csv\")\n",
    "\n",
    "# display the first 5 rows of the data\n",
    "print(df.head(5))\n",
    "\n",
    "# display the last 5 rows of the dada\n",
    "print(df.tail(5))\n",
    "\n",
    "#display the statistics info for the data\n",
    "print(\"************describe*************\")\n",
    "print(df.describe())\n",
    "print(\"***************values*************************\")\n",
    "\n",
    "#transform df to ndarray\n",
    "arr=df.values\n",
    "print(arr)\n",
    "print(\"***************type*************************\")\n",
    "print(type(arr))\n",
    "print(\"**************index**************************\")\n",
    "# print the index names for the row and column separately\n",
    "print(df.index)\n",
    "print(\"**************columns**************************\")\n",
    "print(df.columns)\n",
    "\n",
    "#print the shapse for the data\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 数据选择\n",
    "\n",
    "**数据选择**：在数据预处理过程中，我们往往会对数据集进行切分，只将需要的某些行、列，或者数据块保留下来，输出到下一个流程中去。这也就是所谓的数据选择，或者数据索引。\n",
    "\n",
    "### 5.1 基于数字的索引\n",
    "\n",
    "在dataframe中，如果没有自己设定索引，pandas 会默认从0开始以数字形式作为行索引，并以第一行作为列对应的标签。标签数字索引用到的函数是：\n",
    "```python\n",
    "    pd.iloc(数字索引)\n",
    "```\n",
    "   该方法能够接收的参数有：\n",
    "   \n",
    "   - 整数：pd.iloc[5] \n",
    "   - 数组：pd.iloc([1,2,3])\n",
    "   - 布尔数组\n",
    "   - 返回索引值的函数或参数\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zip Code                  90005.0\n",
      "Total Population          37681.0\n",
      "Median Age                   33.9\n",
      "Total Males               19299.0\n",
      "Total Females             18382.0\n",
      "Total Households          15044.0\n",
      "Average Household Size        2.5\n",
      "Name: 5, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"https://labfile.oss.aliyuncs.com/courses/906/los_census.csv\")\n",
    "\n",
    "#选择一行数据\n",
    "oneRow=df.iloc[5]\n",
    "print(oneRow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zip Code                  90001.0\n",
      "Total Population          57110.0\n",
      "Median Age                   26.6\n",
      "Total Males               28468.0\n",
      "Total Females             28642.0\n",
      "Total Households          12971.0\n",
      "Average Household Size        4.4\n",
      "Name: 1, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# 利用切片选择一组数据\n",
    "\n",
    "mulRow=df.iloc[1]\n",
    "print(mulRow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 那么选择1,3,5行，是不是 df.iloc[1, 3, 5] 这样呢？\n",
    "\n",
    "答案是错误的。df.iloc[] 的 [[行]，[列]] 里面可以同时接受行和列的位置，如果你直接键入 df.iloc[1, 3, 5] 就会报错。\n",
    "\n",
    "所以，很简单。如果你想要选择 1，3，5 行，可以这样做。\n",
    "```python\n",
    "    df.iloc[[1,3,5]]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Zip Code  Total Population  Median Age  Total Males  Total Females  \\\n",
      "1     90001             57110        26.6        28468          28642   \n",
      "3     90003             66266        26.3        32631          33635   \n",
      "5     90005             37681        33.9        19299          18382   \n",
      "\n",
      "   Total Households  Average Household Size  \n",
      "1             12971                    4.40  \n",
      "3             15642                    4.22  \n",
      "5             15044                    2.50  \n"
     ]
    }
   ],
   "source": [
    "oddRow=df.iloc[[1,3,5]]\n",
    "print(oddRow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 上述方法是根据行进行元素的选择，如果要根据列来选择元素可以执行下面的命令\n",
    "```python\n",
    "    df.iloc[:,column nuber|column numbers list]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0          1\n",
      "1      28642\n",
      "2      26347\n",
      "3      33635\n",
      "4      30878\n",
      "5      18382\n",
      "6      28931\n",
      "7      20005\n",
      "8      17850\n",
      "9       1926\n",
      "10     51098\n",
      "11     11610\n",
      "12      4143\n",
      "13      2534\n",
      "14      9153\n",
      "15     24818\n",
      "16     10950\n",
      "17     25540\n",
      "18     33016\n",
      "19     19586\n",
      "20      1161\n",
      "21     33963\n",
      "22     22866\n",
      "23     25204\n",
      "24     21288\n",
      "25     33354\n",
      "26     22789\n",
      "27     12658\n",
      "28     19042\n",
      "29     19770\n",
      "       ...  \n",
      "289    15904\n",
      "290    27902\n",
      "291    15836\n",
      "292    15868\n",
      "293     8198\n",
      "294     3084\n",
      "295     2372\n",
      "296    18195\n",
      "297     1856\n",
      "298    26124\n",
      "299      979\n",
      "300    27774\n",
      "301     2492\n",
      "302      815\n",
      "303      875\n",
      "304     3907\n",
      "305     1543\n",
      "306     1290\n",
      "307    20740\n",
      "308    37167\n",
      "309    33114\n",
      "310     6338\n",
      "311      570\n",
      "312    38515\n",
      "313    25742\n",
      "314    19447\n",
      "315     1017\n",
      "316     9419\n",
      "317      125\n",
      "318     3632\n",
      "Name: Total Females, Length: 319, dtype: int64\n",
      "     Total Population  Total Males  Total Households\n",
      "0                   1            0                 1\n",
      "1               57110        28468             12971\n",
      "2               51223        24876             11731\n",
      "3               66266        32631             15642\n",
      "4               62180        31302             22547\n",
      "5               37681        19299             15044\n",
      "6               59185        30254             18617\n",
      "7               40920        20915             11944\n",
      "8               32327        14477             13841\n",
      "9                3800         1874              2014\n",
      "10             103892        52794             22168\n",
      "11              31103        19493             10327\n",
      "12              11772         7629              6416\n",
      "13               7005         4471              4109\n",
      "14              18986         9833              7420\n",
      "15              47596        22778             16145\n",
      "16              23768        12818              9338\n",
      "17              49310        23770             15493\n",
      "18              64458        31442             23344\n",
      "19              38967        19381             16514\n",
      "20               3951         2790              1561\n",
      "21              67179        33216             17023\n",
      "22              45903        23037             10727\n",
      "23              47452        22248             17903\n",
      "24              42147        20859             21228\n",
      "25              67869        34515             24956\n",
      "26              45151        22362             21929\n",
      "27              28714        16056             14964\n",
      "28              38617        19575             13883\n",
      "29              39316        19546             11156\n",
      "..                ...          ...               ...\n",
      "289             30854        14950              9154\n",
      "290             52735        24833             19315\n",
      "291             30322        14486              9894\n",
      "292             32725        16857              8132\n",
      "293             16763         8565              5370\n",
      "294              6220         3136              2198\n",
      "295              4894         2522              1998\n",
      "296             35533        17338             13062\n",
      "297              3613         1757              1154\n",
      "298             51767        25643             15849\n",
      "299              2031         1052               522\n",
      "300             54366        26592             18650\n",
      "301              5077         2585              2080\n",
      "302              1699          884               623\n",
      "303              4176         3301               647\n",
      "304              7993         4086              2729\n",
      "305              3074         1531              1056\n",
      "306              2932         1642              1079\n",
      "307             39341        18601             14038\n",
      "308             72046        34879             20672\n",
      "309             70918        37804             20964\n",
      "310             13033         6695              3560\n",
      "311              1259          689               569\n",
      "312             74929        36414             20864\n",
      "313             50798        25056             15963\n",
      "314             38158        18711              9690\n",
      "315              2138         1121               816\n",
      "316             18910         9491              6469\n",
      "317               388          263               103\n",
      "318              7285         3653              1982\n",
      "\n",
      "[319 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# choose the fifth column\n",
    "\n",
    "fifth=df.iloc[:,4]\n",
    "print(fifth)\n",
    "\n",
    "# chose the first odd columns\n",
    "\n",
    "oddCol=df.iloc[:,[1,3,5]]\n",
    "print(oddCol)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 根据索引名选择元素\n",
    "<br>\n",
    "\n",
    "除了根据数字索引选择，还可以直接根据标签对应的名称选择。这里用到的方法和上面的 iloc 很相似，少了个 i 为 df.loc[]。\n",
    "\n",
    "df.loc[] 可以接受的类型有：\n",
    "\n",
    " -  单个标签。例如：2 或 'a'，这里的 2 指的是标签而不是索引位置。\n",
    " - 列表或数组包含的标签。例如：['A', 'B', 'C']。\n",
    " - 切片对象。例如：'A':'E'，注意这里和上面切片的不同支持，首尾都包含在内。\n",
    " - 布尔数组。\n",
    " - 可返回标签的函数或参数。\n",
    " \n",
    " ### 备注：对于用户没有设定标签的数组，其默认标签其实和索引是一样的，针对这种情况iloc和loc的参数是相同的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RangeIndex(start=0, stop=319, step=1)\n",
      "Index(['Zip Code', 'Total Population', 'Median Age', 'Total Males',\n",
      "       'Total Females', 'Total Households', 'Average Household Size'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.index)\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zip Code                  90005.0\n",
      "Total Population          37681.0\n",
      "Median Age                   33.9\n",
      "Total Males               19299.0\n",
      "Total Females             18382.0\n",
      "Total Households          15044.0\n",
      "Average Household Size        2.5\n",
      "Name: 5, dtype: float64\n",
      "   Zip Code  Total Population  Median Age  Total Males  Total Females  \\\n",
      "1     90001             57110        26.6        28468          28642   \n",
      "2     90002             51223        25.5        24876          26347   \n",
      "3     90003             66266        26.3        32631          33635   \n",
      "\n",
      "   Total Households  Average Household Size  \n",
      "1             12971                    4.40  \n",
      "2             11731                    4.36  \n",
      "3             15642                    4.22  \n",
      "   Zip Code  Total Population  Median Age  Total Males  Total Females  \\\n",
      "1     90001             57110        26.6        28468          28642   \n",
      "3     90003             66266        26.3        32631          33635   \n",
      "5     90005             37681        33.9        19299          18382   \n",
      "\n",
      "   Total Households  Average Household Size  \n",
      "1             12971                    4.40  \n",
      "3             15642                    4.22  \n",
      "5             15044                    2.50  \n"
     ]
    }
   ],
   "source": [
    "# 因为针对数据而言，行使用的是默认索引，所以所以只是选择行，这里loc与iloc的使用没有差别\n",
    "\n",
    "print(df.loc[5])\n",
    "print(df.loc[1:3])\n",
    "print(df.loc[[1,3,5]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 从上面的df.columns执行结果来看，数据收集人针对数据是添加了语义化的标签名,除了在参数上使用语义化标签外，loc用法与iloc方法选择列并没有太多的不同；\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        1\n",
      "1    57110\n",
      "2    51223\n",
      "3    66266\n",
      "4    62180\n",
      "Name: Total Population, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total Population</th>\n",
       "      <th>Median Age</th>\n",
       "      <th>Total Males</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>38158</td>\n",
       "      <td>28.4</td>\n",
       "      <td>18711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>2138</td>\n",
       "      <td>43.3</td>\n",
       "      <td>1121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>18910</td>\n",
       "      <td>32.4</td>\n",
       "      <td>9491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>388</td>\n",
       "      <td>44.5</td>\n",
       "      <td>263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>7285</td>\n",
       "      <td>30.9</td>\n",
       "      <td>3653</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Total Population  Median Age  Total Males\n",
       "314             38158        28.4        18711\n",
       "315              2138        43.3         1121\n",
       "316             18910        32.4         9491\n",
       "317               388        44.5          263\n",
       "318              7285        30.9         3653"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "popNum=df.loc[:,\"Total Population\"]\n",
    "\n",
    "print(popNum.head(5))\n",
    "\n",
    "ts=df.loc[:,\"Total Population\":\"Total Males\"]\n",
    "ts.tail(5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total Population</th>\n",
       "      <th>Total Males</th>\n",
       "      <th>Total Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57110</td>\n",
       "      <td>28468</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>51223</td>\n",
       "      <td>24876</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>66266</td>\n",
       "      <td>32631</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>62180</td>\n",
       "      <td>31302</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Total Population  Total Males  Total Age\n",
       "0                 1            0        NaN\n",
       "1             57110        28468        NaN\n",
       "2             51223        24876        NaN\n",
       "3             66266        32631        NaN\n",
       "4             62180        31302        NaN"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "td=df.loc[:,[\"Total Population\",\"Total Males\",\"Total Age\"]]\n",
    "td.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 数据的删减\n",
    "\n",
    "在处理数据的时候，在面临有些情况，我们不得不删除数组中部分数据，Pandas提供一下函数用于数据的删除：\n",
    "```python\n",
    "         1.df.drop([索引]，axis=?):根据索引名删除数据；\n",
    "         2.df.drop_duplicates():删除数据中的重复数据；\n",
    "         3.df.dropna():删除数据中有缺失值得行或列；\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.4 数据的填充\n",
    "\n",
    "在真实的生产环境中，我们需要处理的数据文件往往没有想象中的那么美好。其中，很大几率会遇到的情况就是缺失值。缺失值主要是指数据丢失的现象，也就是数据集中的某一块数据不存在。除此之外、存在但明显不正确的数据也被归为缺失值一类。例如，在一个时间序列数据集中，某一段数据突然发生了时间流错乱，那么这一小块数据就是毫无意义的，可以被归为缺失值。\n",
    "\n",
    "### 5.4.1 检测缺失值\n",
    "Pandas 为了更方便地检测缺失值，将不同类型数据的缺失均采用 NaN 标记。这里的 NaN 代表 Not a Number，它仅仅是作为一个标记。例外是，在时间序列里，时间戳的丢失采用 NaT 标记。\n",
    "\n",
    "Pandas 中用于检测缺失值主要用到两个方法，分别是：isna() 和 notna()，故名思意就是「是缺失值」和「不是缺失值」。默认会返回布尔值用于判断。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Time         A         B         C         D         E\n",
      "0 2017-10-03  0.728428  0.519089  0.752957  0.088124  0.391963\n",
      "1        NaT  0.598972       NaN  0.530464       NaN  0.524171\n",
      "2 2017-10-03       NaN  0.331239       NaN  0.087761       NaN\n",
      "3        NaT  0.548077       NaN  0.803766       NaN  0.098108\n",
      "4 2017-10-03       NaN  0.011935       NaN  0.611398       NaN\n",
      "5        NaT  0.313816       NaN  0.834941       NaN  0.940328\n",
      "6 2017-10-03       NaN  0.349780       NaN  0.331600       NaN\n",
      "7        NaT  0.040045       NaN  0.745002       NaN  0.566959\n",
      "8 2017-10-03       NaN  0.658828       NaN  0.241482       NaN\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#create a dataframe\n",
    "df = pd.DataFrame(np.random.rand(9, 5), columns=list('ABCDE'))\n",
    "\n",
    "# 插入 T 列，并打上时间戳,将“column”time插入到第一列\n",
    "df.insert(value=pd.Timestamp('2017-10-3'), loc=0, column='Time')\n",
    "\n",
    "# 将 1, 3, 5 列的 1，3，5 行置为缺失值\n",
    "df.iloc[[1, 3, 5, 7], [0, 2, 4]] = np.nan\n",
    "\n",
    "# 将 2, 4, 6 8 行的 2，4，6 列置为缺失值\n",
    "df.iloc[[2, 4, 6, 8], [1, 3, 5]] = np.nan\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Time      A      B      C      D      E\n",
      "0  False  False  False  False  False  False\n",
      "1   True  False   True  False   True  False\n",
      "2  False   True  False   True  False   True\n",
      "3   True  False   True  False   True  False\n",
      "4  False   True  False   True  False   True\n",
      "5   True  False   True  False   True  False\n",
      "6  False   True  False   True  False   True\n",
      "7   True  False   True  False   True  False\n",
      "8  False   True  False   True  False   True\n"
     ]
    }
   ],
   "source": [
    "a= df.isna()\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "b=df.notna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Time      A      B      C      D      E\n",
      "0   True   True   True   True   True   True\n",
      "1  False   True  False   True  False   True\n",
      "2   True  False   True  False   True  False\n",
      "3  False   True  False   True  False   True\n",
      "4   True  False   True  False   True  False\n",
      "5  False   True  False   True  False   True\n",
      "6   True  False   True  False   True  False\n",
      "7  False   True  False   True  False   True\n",
      "8   True  False   True  False   True  False\n"
     ]
    }
   ],
   "source": [
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Time         A         B         C         D         E\n",
      "0  2017-10-01 00:00:00  0.475584  0.259771  0.034901  0.491540  0.010381\n",
      "1                    0  0.465567  0.000000  0.517693  0.000000  0.551515\n",
      "2  2017-10-01 00:00:00  0.000000  0.212914  0.000000  0.956355  0.000000\n",
      "3                    0  0.790929  0.000000  0.471999  0.000000  0.998210\n",
      "4  2017-10-01 00:00:00  0.000000  0.915548  0.000000  0.221661  0.000000\n",
      "5                    0  0.055812  0.000000  0.126919  0.000000  0.802734\n",
      "6  2017-10-01 00:00:00  0.000000  0.092874  0.000000  0.530040  0.000000\n",
      "7                    0  0.336958  0.000000  0.691019  0.000000  0.257575\n",
      "8  2017-10-01 00:00:00  0.000000  0.466516  0.000000  0.033842  0.000000\n"
     ]
    }
   ],
   "source": [
    "b=df.fillna(0)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4.2 插值填充\n",
    "插值是数值分析中一种方法。简而言之，就是借助于一个函数（线性或非线性），再根据已知数据去求解未知数据的值。插值在数据领域非常常见，它的好处在于，可以尽量去还原数据本身的样子。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      A          B\n",
      "0  1.10   0.210000\n",
      "1  2.20   1.173333\n",
      "2  3.35   2.136667\n",
      "3  4.50   3.100000\n",
      "4  5.70  11.700000\n",
      "5  6.90  13.200000\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'A': [1.1, 2.2, np.nan, 4.5, 5.7, 6.9],\n",
    "                   'B': [.21, np.nan, np.nan, 3.1, 11.7, 13.2]})\n",
    "\n",
    "a=df.interpolate()\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 实验\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29.69911764705882\n",
      "Age的平均值： 29.69911764705882\n",
      "     PassengerId  Survived  Pclass  \\\n",
      "0              1         0       3   \n",
      "1              2         1       1   \n",
      "2              3         1       3   \n",
      "3              4         1       1   \n",
      "4              5         0       3   \n",
      "5              6         0       3   \n",
      "6              7         0       1   \n",
      "7              8         0       3   \n",
      "8              9         1       3   \n",
      "9             10         1       2   \n",
      "10            11         1       3   \n",
      "11            12         1       1   \n",
      "12            13         0       3   \n",
      "13            14         0       3   \n",
      "14            15         0       3   \n",
      "15            16         1       2   \n",
      "16            17         0       3   \n",
      "17            18         1       2   \n",
      "18            19         0       3   \n",
      "19            20         1       3   \n",
      "20            21         0       2   \n",
      "21            22         1       2   \n",
      "22            23         1       3   \n",
      "23            24         1       1   \n",
      "24            25         0       3   \n",
      "25            26         1       3   \n",
      "26            27         0       3   \n",
      "27            28         0       1   \n",
      "28            29         1       3   \n",
      "29            30         0       3   \n",
      "..           ...       ...     ...   \n",
      "861          862         0       2   \n",
      "862          863         1       1   \n",
      "863          864         0       3   \n",
      "864          865         0       2   \n",
      "865          866         1       2   \n",
      "866          867         1       2   \n",
      "867          868         0       1   \n",
      "868          869         0       3   \n",
      "869          870         1       3   \n",
      "870          871         0       3   \n",
      "871          872         1       1   \n",
      "872          873         0       1   \n",
      "873          874         0       3   \n",
      "874          875         1       2   \n",
      "875          876         1       3   \n",
      "876          877         0       3   \n",
      "877          878         0       3   \n",
      "878          879         0       3   \n",
      "879          880         1       1   \n",
      "880          881         1       2   \n",
      "881          882         0       3   \n",
      "882          883         0       3   \n",
      "883          884         0       2   \n",
      "884          885         0       3   \n",
      "885          886         0       3   \n",
      "886          887         0       2   \n",
      "887          888         1       1   \n",
      "888          889         0       3   \n",
      "889          890         1       1   \n",
      "890          891         0       3   \n",
      "\n",
      "                                                  Name     Sex        Age  \\\n",
      "0                              Braund, Mr. Owen Harris    male  22.000000   \n",
      "1    Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.000000   \n",
      "2                               Heikkinen, Miss. Laina  female  26.000000   \n",
      "3         Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.000000   \n",
      "4                             Allen, Mr. William Henry    male  35.000000   \n",
      "5                                     Moran, Mr. James    male  29.699118   \n",
      "6                              McCarthy, Mr. Timothy J    male  54.000000   \n",
      "7                       Palsson, Master. Gosta Leonard    male   2.000000   \n",
      "8    Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)  female  27.000000   \n",
      "9                  Nasser, Mrs. Nicholas (Adele Achem)  female  14.000000   \n",
      "10                     Sandstrom, Miss. Marguerite Rut  female   4.000000   \n",
      "11                            Bonnell, Miss. Elizabeth  female  58.000000   \n",
      "12                      Saundercock, Mr. William Henry    male  20.000000   \n",
      "13                         Andersson, Mr. Anders Johan    male  39.000000   \n",
      "14                Vestrom, Miss. Hulda Amanda Adolfina  female  14.000000   \n",
      "15                    Hewlett, Mrs. (Mary D Kingcome)   female  55.000000   \n",
      "16                                Rice, Master. Eugene    male   2.000000   \n",
      "17                        Williams, Mr. Charles Eugene    male  29.699118   \n",
      "18   Vander Planke, Mrs. Julius (Emelia Maria Vande...  female  31.000000   \n",
      "19                             Masselmani, Mrs. Fatima  female  29.699118   \n",
      "20                                Fynney, Mr. Joseph J    male  35.000000   \n",
      "21                               Beesley, Mr. Lawrence    male  34.000000   \n",
      "22                         McGowan, Miss. Anna \"Annie\"  female  15.000000   \n",
      "23                        Sloper, Mr. William Thompson    male  28.000000   \n",
      "24                       Palsson, Miss. Torborg Danira  female   8.000000   \n",
      "25   Asplund, Mrs. Carl Oscar (Selma Augusta Emilia...  female  38.000000   \n",
      "26                             Emir, Mr. Farred Chehab    male  29.699118   \n",
      "27                      Fortune, Mr. Charles Alexander    male  19.000000   \n",
      "28                       O'Dwyer, Miss. Ellen \"Nellie\"  female  29.699118   \n",
      "29                                 Todoroff, Mr. Lalio    male  29.699118   \n",
      "..                                                 ...     ...        ...   \n",
      "861                        Giles, Mr. Frederick Edward    male  21.000000   \n",
      "862  Swift, Mrs. Frederick Joel (Margaret Welles Ba...  female  48.000000   \n",
      "863                  Sage, Miss. Dorothy Edith \"Dolly\"  female  29.699118   \n",
      "864                             Gill, Mr. John William    male  24.000000   \n",
      "865                           Bystrom, Mrs. (Karolina)  female  42.000000   \n",
      "866                       Duran y More, Miss. Asuncion  female  27.000000   \n",
      "867               Roebling, Mr. Washington Augustus II    male  31.000000   \n",
      "868                        van Melkebeke, Mr. Philemon    male  29.699118   \n",
      "869                    Johnson, Master. Harold Theodor    male   4.000000   \n",
      "870                                  Balkic, Mr. Cerin    male  26.000000   \n",
      "871   Beckwith, Mrs. Richard Leonard (Sallie Monypeny)  female  47.000000   \n",
      "872                           Carlsson, Mr. Frans Olof    male  33.000000   \n",
      "873                        Vander Cruyssen, Mr. Victor    male  47.000000   \n",
      "874              Abelson, Mrs. Samuel (Hannah Wizosky)  female  28.000000   \n",
      "875                   Najib, Miss. Adele Kiamie \"Jane\"  female  15.000000   \n",
      "876                      Gustafsson, Mr. Alfred Ossian    male  20.000000   \n",
      "877                               Petroff, Mr. Nedelio    male  19.000000   \n",
      "878                                 Laleff, Mr. Kristo    male  29.699118   \n",
      "879      Potter, Mrs. Thomas Jr (Lily Alexenia Wilson)  female  56.000000   \n",
      "880       Shelley, Mrs. William (Imanita Parrish Hall)  female  25.000000   \n",
      "881                                 Markun, Mr. Johann    male  33.000000   \n",
      "882                       Dahlberg, Miss. Gerda Ulrika  female  22.000000   \n",
      "883                      Banfield, Mr. Frederick James    male  28.000000   \n",
      "884                             Sutehall, Mr. Henry Jr    male  25.000000   \n",
      "885               Rice, Mrs. William (Margaret Norton)  female  39.000000   \n",
      "886                              Montvila, Rev. Juozas    male  27.000000   \n",
      "887                       Graham, Miss. Margaret Edith  female  19.000000   \n",
      "888           Johnston, Miss. Catherine Helen \"Carrie\"  female  29.699118   \n",
      "889                              Behr, Mr. Karl Howell    male  26.000000   \n",
      "890                                Dooley, Mr. Patrick    male  32.000000   \n",
      "\n",
      "     SibSp  Parch            Ticket      Fare        Cabin Embarked  \n",
      "0        1      0         A/5 21171    7.2500          NaN        S  \n",
      "1        1      0          PC 17599   71.2833          C85        C  \n",
      "2        0      0  STON/O2. 3101282    7.9250          NaN        S  \n",
      "3        1      0            113803   53.1000         C123        S  \n",
      "4        0      0            373450    8.0500          NaN        S  \n",
      "5        0      0            330877    8.4583          NaN        Q  \n",
      "6        0      0             17463   51.8625          E46        S  \n",
      "7        3      1            349909   21.0750          NaN        S  \n",
      "8        0      2            347742   11.1333          NaN        S  \n",
      "9        1      0            237736   30.0708          NaN        C  \n",
      "10       1      1           PP 9549   16.7000           G6        S  \n",
      "11       0      0            113783   26.5500         C103        S  \n",
      "12       0      0         A/5. 2151    8.0500          NaN        S  \n",
      "13       1      5            347082   31.2750          NaN        S  \n",
      "14       0      0            350406    7.8542          NaN        S  \n",
      "15       0      0            248706   16.0000          NaN        S  \n",
      "16       4      1            382652   29.1250          NaN        Q  \n",
      "17       0      0            244373   13.0000          NaN        S  \n",
      "18       1      0            345763   18.0000          NaN        S  \n",
      "19       0      0              2649    7.2250          NaN        C  \n",
      "20       0      0            239865   26.0000          NaN        S  \n",
      "21       0      0            248698   13.0000          D56        S  \n",
      "22       0      0            330923    8.0292          NaN        Q  \n",
      "23       0      0            113788   35.5000           A6        S  \n",
      "24       3      1            349909   21.0750          NaN        S  \n",
      "25       1      5            347077   31.3875          NaN        S  \n",
      "26       0      0              2631    7.2250          NaN        C  \n",
      "27       3      2             19950  263.0000  C23 C25 C27        S  \n",
      "28       0      0            330959    7.8792          NaN        Q  \n",
      "29       0      0            349216    7.8958          NaN        S  \n",
      "..     ...    ...               ...       ...          ...      ...  \n",
      "861      1      0             28134   11.5000          NaN        S  \n",
      "862      0      0             17466   25.9292          D17        S  \n",
      "863      8      2          CA. 2343   69.5500          NaN        S  \n",
      "864      0      0            233866   13.0000          NaN        S  \n",
      "865      0      0            236852   13.0000          NaN        S  \n",
      "866      1      0     SC/PARIS 2149   13.8583          NaN        C  \n",
      "867      0      0          PC 17590   50.4958          A24        S  \n",
      "868      0      0            345777    9.5000          NaN        S  \n",
      "869      1      1            347742   11.1333          NaN        S  \n",
      "870      0      0            349248    7.8958          NaN        S  \n",
      "871      1      1             11751   52.5542          D35        S  \n",
      "872      0      0               695    5.0000  B51 B53 B55        S  \n",
      "873      0      0            345765    9.0000          NaN        S  \n",
      "874      1      0         P/PP 3381   24.0000          NaN        C  \n",
      "875      0      0              2667    7.2250          NaN        C  \n",
      "876      0      0              7534    9.8458          NaN        S  \n",
      "877      0      0            349212    7.8958          NaN        S  \n",
      "878      0      0            349217    7.8958          NaN        S  \n",
      "879      0      1             11767   83.1583          C50        C  \n",
      "880      0      1            230433   26.0000          NaN        S  \n",
      "881      0      0            349257    7.8958          NaN        S  \n",
      "882      0      0              7552   10.5167          NaN        S  \n",
      "883      0      0  C.A./SOTON 34068   10.5000          NaN        S  \n",
      "884      0      0   SOTON/OQ 392076    7.0500          NaN        S  \n",
      "885      0      5            382652   29.1250          NaN        Q  \n",
      "886      0      0            211536   13.0000          NaN        S  \n",
      "887      0      0            112053   30.0000          B42        S  \n",
      "888      1      2        W./C. 6607   23.4500          NaN        S  \n",
      "889      0      0            111369   30.0000         C148        C  \n",
      "890      0      0            370376    7.7500          NaN        Q  \n",
      "\n",
      "[891 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"./titanic/train.csv\")\n",
    "#print(df.head())\n",
    "#print(df.tail(3))\n",
    "#\n",
    "#检查是否是na。检查出来只有age和cabin有数据为nan\n",
    "#print(df.isna())\n",
    "\n",
    "#查看数据样式\n",
    "#print(df)\n",
    "\n",
    "#计算属性为age的平均值\n",
    "age_averge=df['Age'].mean()\n",
    "#输出age值\n",
    "print(age_averge)\n",
    "dd=df\n",
    "#dd['Z']=dd['Z'].fillna('lg')\n",
    "print(\"Age的平均值：\",age_averge)\n",
    "dd['Age']=dd['Age'].fillna(age_averge)\n",
    "print(dd)\n",
    "\n",
    "#填充cabin\n",
    "#cabin缺失太多删除属性\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
