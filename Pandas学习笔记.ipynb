{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pandas学习笔记"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas:Python Data Analysis Library，Pandas 纳入了大量库和一些标准的数据模型，提供了高效地操作大型数据集所需的工具。pandas提供了大量能使我们快速便捷地处理数据的函数和方法。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "创建Series 可以简单地被认为是一维的数组。 Series 和一维数组最主要的区别在于 Series 类型具有索引（ index ）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      1\n",
      "1     34\n",
      "2     na\n",
      "3    NaN\n",
      "4     32\n",
      "5      2\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "s = pd.Series([1,34,'na',np.nan,32,2])\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame：\n",
    "* 一个表格型的数据结构。既有行索引也有列索引"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************numpy****************\n",
      "          0         1         2         3\n",
      "0 -1.013258  0.046903 -0.158254 -0.606532\n",
      "1  0.228383  0.132861 -1.138817 -0.674740\n",
      "2 -0.566353  0.248678 -2.326542  0.033787\n",
      "3  0.347301  0.234953  1.553884  0.793905\n",
      "4  0.831964  0.219125 -1.135724 -0.686983\n",
      "5 -0.563174  0.605001  0.236583 -0.022705\n",
      "                   A         B         C         D\n",
      "2018-01-01 -1.608787 -3.791448  1.206857 -1.797146\n",
      "2018-01-02 -1.223969 -0.502268 -0.254948 -0.142938\n",
      "2018-01-03 -1.441328 -0.304031  0.441272 -0.251655\n",
      "2018-01-04  0.958799  0.663686 -0.010626  1.133525\n",
      "2018-01-05  2.178581  0.445857 -1.104544  1.351510\n",
      "2018-01-06  0.700029 -0.570734  0.774662  1.846533\n",
      "*****************字典****************\n",
      "0     Jack\n",
      "1    Bella\n",
      "2      Bob\n",
      "3    Alice\n",
      "Name: E, dtype: category\n",
      "Categories (4, object): [Alice, Bella, Bob, Jack]\n",
      "*****************************\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "dates = pd.date_range('2018-1-1',periods = 6)\n",
    "# print(dates)\n",
    "\n",
    "print('*****************numpy****************')\n",
    "df = pd.DataFrame(np.random.randn(6,4))#默认命名，行/列索引为默认数字\n",
    "print(df)\n",
    "\n",
    "df1 = pd.DataFrame(np.random.randn(6,4),index = dates,columns = ['A','B','C','D']) #指定命名\n",
    "print(df1)\n",
    "\n",
    "print('*****************字典****************')\n",
    "df2 = pd.DataFrame({'A':1,\n",
    "                    'B':2,\n",
    "                    'C':3,\n",
    "                    'D':4,\n",
    "                    'E':pd.Categorical(['Jack','Bella','Bob','Alice']),\n",
    "                    'F':'str',\n",
    "                   })\n",
    "print(df2)\n",
    "print(\"*****************************\")\n",
    "# print(df2.values)\n",
    "# print('*****************属性****************')\n",
    "# print(df2.dtypes)#数据类型\n",
    "# print(df2.index)#行\n",
    "# print(df2.columns)#列\n",
    "# print(df2.values)#值\n",
    "# print(df2.sort_index())#按行排序\n",
    "# print(df2.sort_values(by='E'))#按E排序"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pandas数据索引"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 中括号的索引注意：\n",
    "* （1）单值索引只能索引列，不能索引某一行，\n",
    "* （2）索引某一行，不能写成df['a']或df['a',:]\n",
    "    索引多列，可以写成df[['A','B']]\n",
    "* （3）切片只能索引多行\n",
    "    切片多列可以写成df.loc[:,'A':'C']\n",
    "* （4）用loc/iloc[]的索引\n",
    "    df.loc[:,'A']表示索引A列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    A   B   C   D\n",
      "a   0   1   2   3\n",
      "b   4   5   6   7\n",
      "c   8   9  10  11\n",
      "d  12  13  14  15\n",
      "********************数据索引******************\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cannot do label indexing on <class 'pandas.core.indexes.base.Index'> with these indexers [2] of <class 'int'>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-63-265c8a95ea46>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m# loc:select by label\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;31m# print(df.iloc[1,2])#iloc: select by position\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1498\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1499\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1500\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1501\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1502\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1910\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1911\u001b[0m         \u001b[1;31m# fall thru to straight lookup\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1912\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_key\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1913\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_label\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1914\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_validate_key\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1797\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1798\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_list_like_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1799\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_convert_scalar_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1800\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1801\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_convert_scalar_indexer\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[0max\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;31m# a scalar\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_convert_scalar_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    263\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    264\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_convert_slice_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36m_convert_scalar_indexer\u001b[1;34m(self, key, kind)\u001b[0m\n\u001b[0;32m   2879\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mkind\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'loc'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2880\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mholds_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2881\u001b[1;33m                     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_invalid_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'label'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2882\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2883\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36m_invalid_indexer\u001b[1;34m(self, form, key)\u001b[0m\n\u001b[0;32m   3065\u001b[0m                         \"indexers [{key}] of {kind}\".format(\n\u001b[0;32m   3066\u001b[0m                             \u001b[0mform\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mform\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mklass\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3067\u001b[1;33m                             kind=type(key)))\n\u001b[0m\u001b[0;32m   3068\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3069\u001b[0m     \u001b[1;31m# --------------------------------------------------------------------\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: cannot do label indexing on <class 'pandas.core.indexes.base.Index'> with these indexers [2] of <class 'int'>"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "dates = pd.date_range('2018-1-1',periods=6)\n",
    "# df=pd.DataFrame(np.arange(24).reshape(6,4),index=dates,columns=['A','B','C','D'])\n",
    "df = pd.DataFrame(np.arange(16).reshape(4,4),index=list('abcd'),columns=list('ABCD'))\n",
    "print(df)\n",
    "\n",
    "print('********************数据索引******************')\n",
    "#*****单值索引只能索引列****\n",
    "# print(df['B'])\n",
    "# df.B\n",
    "# print(df['2018-1-1'])\n",
    "\n",
    "\n",
    "print(df.loc[:,'A'])# loc:select by label\n",
    "# print(df.iloc[1,2])#iloc: select by position\n",
    "\n",
    "# print(df.ix[3,['A']])#mix：both iloc and loc（deprecated）\n",
    "# print(df[df.C>7])#Boolean index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2656\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2657\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2658\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 0",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-66418285b977>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mdf6\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m12\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'abcd'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# print(df6)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf6\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m#取a列\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;31m# df6[['a','b']]#取a、b列\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2925\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2926\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2927\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2928\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2929\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2657\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2658\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2659\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2660\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2661\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "df6=pd.DataFrame(np.arange(12).reshape((3,4)),columns=list('abcd'))\n",
    "# print(df6)\n",
    "print(df6[0])#取a列\n",
    "# df6[['a','b']]#取a、b列"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据修改"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             A   B   C   D\n",
      "2018-01-01   0   1   2   3\n",
      "2018-01-02   4   5   6   7\n",
      "2018-01-03   8   9  10  11\n",
      "2018-01-04  12  13  14  15\n",
      "2018-01-05  16  17  18  19\n",
      "2018-01-06  20  21  22  23\n",
      "********************数据更改******************\n",
      "             A   B   C   D   E\n",
      "2018-01-01   0   1   2   3   1\n",
      "2018-01-02   4   5   6   7  23\n",
      "2018-01-03   8   9  10  11   4\n",
      "2018-01-04  12  13  14  15   5\n",
      "2018-01-05  16  17  18  19   6\n",
      "2018-01-06  20  21  22  23   7\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "dates = pd.date_range('2018-1-1',periods=6)\n",
    "df=pd.DataFrame(np.arange(24).reshape(6,4),index=dates,columns=['A','B','C','D'])\n",
    "print(df)\n",
    "\n",
    "print('********************数据更改******************')\n",
    "# df.loc['2018-1-1','A']=1\n",
    "# df.iloc[1,1]=53\n",
    "# df.B[df.A>5] = 0 #将B中的大于5的数改为0\n",
    "\n",
    "df['E'] = pd.Series([1,23,4,5,6,7],index=dates)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 处理丢失数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dropna(:，how=‘any/all’)：any为只要有一个就丢掉，all为所有为null才丢掉\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************已丢失数据******************\n",
      "             A   B     C     D\n",
      "2018-01-01   0   1   2.0   3.0\n",
      "2018-01-02   4   5   NaN   7.0\n",
      "2018-01-03   8   9  10.0   NaN\n",
      "2018-01-04  12  13  14.0  15.0\n",
      "2018-01-05  16  17  18.0  19.0\n",
      "2018-01-06  20  21  22.0  23.0\n",
      "                A      B      C      D\n",
      "2018-01-01  False  False  False  False\n",
      "2018-01-02  False  False   True  False\n",
      "2018-01-03  False  False  False   True\n",
      "2018-01-04  False  False  False  False\n",
      "2018-01-05  False  False  False  False\n",
      "2018-01-06  False  False  False  False\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "dates = pd.date_range('2018-1-1',periods=6)\n",
    "df=pd.DataFrame(np.arange(24).reshape(6,4),index=dates,columns=['A','B','C','D'])\n",
    "\n",
    "print('********************已丢失数据******************')\n",
    "df.iloc[1,2]=np.nan\n",
    "df.iloc[2,3]=np.nan\n",
    "print(df)\n",
    "\n",
    "# print('********************丢掉缺失数据******************')\n",
    "# print(df.dropna(axis=1,how='any'))\n",
    "# print('********************填充缺失数据******************')\n",
    "# print(df.fillna(value=0))\n",
    "# print('********************判断数据中是否为空******************')\n",
    "print(df.isnull())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 读取和保存"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 读取数据时，路径如果在同一个目录下，则需要加入目录目录因用 “/”表示\n",
    "* 主要文件读取类型：_excel,_table,_html,_json,_sql,_pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   StudentID Name  Age  Class\n",
      "0     318070   王浩   18      1\n",
      "1     318071  伏娇燕   19      2\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "oData=open(\"C:/Users/Administrator.SG-20170929NLXP/Desktop/students.csv\")\n",
    "#_excel,_table,_html,_json,_sql,_pickle\n",
    "\n",
    "Data=pd.read_csv(oData)\n",
    "print(Data)\n",
    "#保存到默认文件夹下\n",
    "Data.to_pickle('student.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 合并数据Concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     a    b    c    d\n",
      "1  0.0  0.0  0.0  0.0\n",
      "2  0.0  0.0  0.0  0.0\n",
      "3  0.0  0.0  0.0  0.0\n",
      "     b    c    d    e\n",
      "2  1.0  1.0  1.0  1.0\n",
      "3  1.0  1.0  1.0  1.0\n",
      "4  1.0  1.0  1.0  1.0\n",
      "     a    b    c    d    b    c    d    e\n",
      "1  0.0  0.0  0.0  0.0  NaN  NaN  NaN  NaN\n",
      "2  0.0  0.0  0.0  0.0  1.0  1.0  1.0  1.0\n",
      "3  0.0  0.0  0.0  0.0  1.0  1.0  1.0  1.0\n",
      "     a    b    c    d    e\n",
      "0  0.0  0.0  0.0  0.0  NaN\n",
      "1  0.0  0.0  0.0  0.0  NaN\n",
      "2  0.0  0.0  0.0  0.0  NaN\n",
      "0  1.0  1.0  1.0  1.0  NaN\n",
      "1  1.0  1.0  1.0  1.0  NaN\n",
      "2  1.0  1.0  1.0  1.0  NaN\n",
      "2  NaN  1.0  1.0  1.0  1.0\n",
      "3  NaN  1.0  1.0  1.0  1.0\n",
      "4  NaN  1.0  1.0  1.0  1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\pandas\\core\\frame.py:6211: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  sort=sort)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "# print('************列一致**********')\n",
    "pd1=pd.DataFrame(np.ones((3,4))*1,columns=['a','b','c','d'])\n",
    "pd2=pd.DataFrame(np.ones((3,4))*2,columns=['a','b','c','d'])\n",
    "pd3=pd.DataFrame(np.ones((3,4))*3,columns=['a','b','c','d'])\n",
    "res=pd.concat([pd1,pd2,pd3],axis=0,ignore_index=True)#ignore_index表示合并数据过后忽略行数\n",
    "# print(res)\n",
    "\n",
    "# print('************行/列不一致**********')\n",
    "df1=pd.DataFrame(np.ones((3,4))*0,columns=['a','b','c','d'],index=[1,2,3])\n",
    "df2=pd.DataFrame(np.ones((3,4))*1,columns=['b','c','d','e'],index=[2,3,4])\n",
    "\n",
    "        #join, ('inner', 'outer')\n",
    "\n",
    "res1=pd.concat([df1, df2],axis=1) # default for how='inner'\n",
    "# print(res1)\n",
    "# print('************行**********')\n",
    "\n",
    "# res1=pd.concat([df1, df2],axis=1,join='inner')#将行/列相同的留下，将不同的裁剪\n",
    "\n",
    "        #join_axes\n",
    "res1=pd.concat([df1, df2],axis=1,join_axes=[df1.index])#将两个按照df1的行号进行合并\n",
    "print(df1)\n",
    "print(df2)\n",
    "print(res1)\n",
    "        #append\n",
    "df1=pd.DataFrame(np.ones((3,4))*0,columns=['a','b','c','d'])\n",
    "df2=pd.DataFrame(np.ones((3,4))*1,columns=['a','b','c','d'])\n",
    "df3=pd.DataFrame(np.ones((3,4))*1,columns=['b','c','d','e'],index=[2,3,4])\n",
    "# res1=df1.append(df2,ignore_index=True)\n",
    "res2=df1.append([df2, df3])\n",
    "\n",
    "\n",
    "print(res2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 合并数据merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********oneKey**********\n",
      "  key   A   B\n",
      "0  K0  A0  B0\n",
      "1  K1  A1  B1\n",
      "2  K2  A2  B2\n",
      "3  K3  A3  B3\n",
      "  key   C   D\n",
      "0  K0  C0  D0\n",
      "1  K1  C1  D1\n",
      "2  K2  C2  D2\n",
      "3  K3  C3  D3\n",
      "  key   A   B   C   D\n",
      "0  K0  A0  B0  C0  D0\n",
      "1  K1  A1  B1  C1  D1\n",
      "2  K2  A2  B2  C2  D2\n",
      "3  K3  A3  B3  C3  D3\n",
      "***********TwoKeys**********\n",
      "  key1 key2   A   B\n",
      "0   K0   K0  A0  B0\n",
      "1   K0   K1  A1  B1\n",
      "2   K1   K0  A2  B2\n",
      "3   K2   K1  A3  B3\n",
      "  key1 key2   C   D\n",
      "0   K0   K0  C0  D0\n",
      "1   K1   K0  C1  D1\n",
      "2   K1   K0  C2  D2\n",
      "3   K2   K0  C3  D3\n",
      "  key1 key2   A   B    C    D\n",
      "0   K0   K0  A0  B0   C0   D0\n",
      "1   K0   K1  A1  B1  NaN  NaN\n",
      "2   K1   K0  A2  B2   C1   D1\n",
      "3   K1   K0  A2  B2   C2   D2\n",
      "4   K2   K1  A3  B3  NaN  NaN\n",
      "***********indicator**********\n",
      "   col1 col_left\n",
      "0     0        a\n",
      "1     1        b\n",
      "   col1  col_right\n",
      "0     1          2\n",
      "1     2          2\n",
      "2     2          2\n",
      "   col1 col_left  col_right      _merge\n",
      "0     0        a        NaN   left_only\n",
      "1     1        b        2.0        both\n",
      "2     2      NaN        2.0  right_only\n",
      "3     2      NaN        2.0  right_only\n",
      "***********merge by index**********\n",
      "     A   B\n",
      "K0  A0  B0\n",
      "K1  A1  B1\n",
      "K2  A2  B2\n",
      "     C   D\n",
      "K0  C0  D0\n",
      "K2  C2  D2\n",
      "K3  C3  D3\n",
      "      A    B    C    D\n",
      "K0   A0   B0   C0   D0\n",
      "K1   A1   B1  NaN  NaN\n",
      "K2   A2   B2   C2   D2\n",
      "K3  NaN  NaN   C3   D3\n",
      "***********handle overlapping**********\n",
      "    k  age_boy  age_girl\n",
      "0  K0        1         4\n",
      "1  K0        1         5\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "print('***********oneKey**********')\n",
    "left = pd.DataFrame({'key': ['K0', 'K1', 'K2', 'K3'],\n",
    "                                  'A': ['A0', 'A1', 'A2', 'A3'],\n",
    "                                  'B': ['B0', 'B1', 'B2', 'B3']})\n",
    "right = pd.DataFrame({'key': ['K0', 'K1', 'K2', 'K3'],\n",
    "                                    'C': ['C0', 'C1', 'C2', 'C3'],\n",
    "                                    'D': ['D0', 'D1', 'D2', 'D3']})\n",
    "print(left)\n",
    "print(right)\n",
    "res = pd.merge(left, right, on='key')\n",
    "print(res)\n",
    "\n",
    "print('***********TwoKeys**********')\n",
    "left = pd.DataFrame({'key1': ['K0', 'K0', 'K1', 'K2'],\n",
    "                             'key2': ['K0', 'K1', 'K0', 'K1'],\n",
    "                             'A': ['A0', 'A1', 'A2', 'A3'],\n",
    "                             'B': ['B0', 'B1', 'B2', 'B3']})\n",
    "right = pd.DataFrame({'key1': ['K0', 'K1', 'K1', 'K2'],\n",
    "                              'key2': ['K0', 'K0', 'K0', 'K0'],\n",
    "                              'C': ['C0', 'C1', 'C2', 'C3'],\n",
    "                              'D': ['D0', 'D1', 'D2', 'D3']})\n",
    "\n",
    "print(left)\n",
    "print(right)\n",
    "res = pd.merge(left, right, on=['key1', 'key2'], how='inner')  # default for how='inner'\n",
    "# how = ['left', 'right', 'outer', 'inner']\n",
    "res = pd.merge(left, right, on=['key1', 'key2'], how='left') #按照左边的来合并\n",
    "print(res)\n",
    "\n",
    "print('***********indicator**********')\n",
    "df1 = pd.DataFrame({'col1':[0,1], 'col_left':['a','b']})\n",
    "df2 = pd.DataFrame({'col1':[1,2,2],'col_right':[2,2,2]})\n",
    "print(df1)\n",
    "print(df2)\n",
    "res = pd.merge(df1, df2, on='col1', how='outer', indicator=True)\n",
    "# give the indicator a custom name\n",
    "\n",
    "res = pd.merge(df1, df2, on='col1', how='outer', indicator=True)#indicator表示合并记录而'indicator_column'则是新行名称\n",
    "print(res)\n",
    "\n",
    "\n",
    "print('***********merge by index**********')\n",
    "left = pd.DataFrame({'A': ['A0', 'A1', 'A2'],\n",
    "                                  'B': ['B0', 'B1', 'B2']},\n",
    "                                  index=['K0', 'K1', 'K2'])\n",
    "right = pd.DataFrame({'C': ['C0', 'C2', 'C3'],\n",
    "                                     'D': ['D0', 'D2', 'D3']},\n",
    "                                      index=['K0', 'K2', 'K3'])\n",
    "print(left)\n",
    "print(right)\n",
    "# left_index and right_index\n",
    "res = pd.merge(left, right, left_index=True, right_index=True, how='outer')\n",
    "print(res)\n",
    "\n",
    "print('***********handle overlapping**********')\n",
    "boys = pd.DataFrame({'k': ['K0', 'K1', 'K2'], 'age': [1, 2, 3]})\n",
    "girls = pd.DataFrame({'k': ['K0', 'K0', 'K3'], 'age': [4, 5, 6]})\n",
    "res = pd.merge(boys, girls, on='k', suffixes=['_boy', '_girl'], how='inner')#使用suffixes解决overlapping的问题\n",
    "print(res)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot画图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# print('***********Series**********')\n",
    "# data = pd.Series(np.random.randn(1000), index=np.arange(1000))\n",
    "# data = data.cumsum()\n",
    "# data.plot()\n",
    "# data.show()\n",
    "\n",
    "# print('***********DataFrame**********')\n",
    "data = pd.DataFrame(np.random.randn(1000, 4), index=np.arange(1000), columns=list(\"ABCD\"))\n",
    "data = data.cumsum()\n",
    "# plot methods:\n",
    "# 'bar', 'hist', 'box', 'kde', 'area', scatter', hexbin', 'pie'\n",
    "ax = data.plot.scatter(x='A', y='B', color='DarkBlue', label=\"Class 1\")\n",
    "data.plot.scatter(x='A', y='C', color='LightGreen', label='Class 2', ax=ax)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
